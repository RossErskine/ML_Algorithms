{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2c033c",
   "metadata": {},
   "source": [
    "# Forward selection using Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a71f89",
   "metadata": {},
   "source": [
    "## Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81dbd59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8705a899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "770f4ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.001, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y, single_feature= False):\n",
    "        n_samples, n_features = X.shape \n",
    "\n",
    "        # init parameters\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # gradient descent\n",
    "        for _ in range(self.n_iters):\n",
    "            # approximate y with linear combination of weights and x, plus bias\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            # apply sigmoid function\n",
    "            y_predicted = self._sigmoid(linear_model)\n",
    "\n",
    "            # compute gradients\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "            # update parameters\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self._sigmoid(linear_model)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return np.array(y_predicted_cls)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd6bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a3e402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load csv file \n",
    "df = pd.read_csv('../datasets/mushrooms.csv', index_col=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ac016f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0e8c580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   class                     8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8ef819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def label_encoded(feat):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(feat)\n",
    "    print(feat.name,le.classes_)\n",
    "#     print(le.classes_)\n",
    "    return le.transform(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a415a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ['e' 'p']\n",
      "cap-shape ['b' 'c' 'f' 'k' 's' 'x']\n",
      "cap-surface ['f' 'g' 's' 'y']\n",
      "cap-color ['b' 'c' 'e' 'g' 'n' 'p' 'r' 'u' 'w' 'y']\n",
      "bruises ['f' 't']\n",
      "odor ['a' 'c' 'f' 'l' 'm' 'n' 'p' 's' 'y']\n",
      "gill-attachment ['a' 'f']\n",
      "gill-spacing ['c' 'w']\n",
      "gill-size ['b' 'n']\n",
      "gill-color ['b' 'e' 'g' 'h' 'k' 'n' 'o' 'p' 'r' 'u' 'w' 'y']\n",
      "stalk-shape ['e' 't']\n",
      "stalk-root ['?' 'b' 'c' 'e' 'r']\n",
      "stalk-surface-above-ring ['f' 'k' 's' 'y']\n",
      "stalk-surface-below-ring ['f' 'k' 's' 'y']\n",
      "stalk-color-above-ring ['b' 'c' 'e' 'g' 'n' 'o' 'p' 'w' 'y']\n",
      "stalk-color-below-ring ['b' 'c' 'e' 'g' 'n' 'o' 'p' 'w' 'y']\n",
      "veil-type ['p']\n",
      "veil-color ['n' 'o' 'w' 'y']\n",
      "ring-number ['n' 'o' 't']\n",
      "ring-type ['e' 'f' 'l' 'n' 'p']\n",
      "spore-print-color ['b' 'h' 'k' 'n' 'o' 'r' 'u' 'w' 'y']\n",
      "population ['a' 'c' 'n' 's' 'v' 'y']\n",
      "habitat ['d' 'g' 'l' 'm' 'p' 'u' 'w']\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    df[str(col)] = label_encoded(df[str(col)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6270cd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
       "0      1          5            2          4        1     6                1   \n",
       "1      0          5            2          9        1     0                1   \n",
       "2      0          0            2          8        1     3                1   \n",
       "3      1          5            3          8        1     6                1   \n",
       "4      0          5            2          3        0     5                1   \n",
       "\n",
       "   gill-spacing  gill-size  gill-color  ...  stalk-surface-below-ring  \\\n",
       "0             0          1           4  ...                         2   \n",
       "1             0          0           4  ...                         2   \n",
       "2             0          0           5  ...                         2   \n",
       "3             0          1           5  ...                         2   \n",
       "4             1          0           4  ...                         2   \n",
       "\n",
       "   stalk-color-above-ring  stalk-color-below-ring  veil-type  veil-color  \\\n",
       "0                       7                       7          0           2   \n",
       "1                       7                       7          0           2   \n",
       "2                       7                       7          0           2   \n",
       "3                       7                       7          0           2   \n",
       "4                       7                       7          0           2   \n",
       "\n",
       "   ring-number  ring-type  spore-print-color  population  habitat  \n",
       "0            1          4                  2           3        5  \n",
       "1            1          4                  3           2        1  \n",
       "2            1          4                  3           2        3  \n",
       "3            1          4                  2           3        5  \n",
       "4            1          0                  3           0        1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b29a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['class'],axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69dd3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=3, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7699363",
   "metadata": {},
   "source": [
    "# Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a483f2",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68535614",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates=[0.1,0.01,0.001,0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cef40866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypTune(X_train, y_train, X_val, y_val):\n",
    "    scores = []\n",
    "    for lr in learning_rates:\n",
    "        logReg = LogisticRegression(lr)\n",
    "        logReg.fit(X_train, y_train)\n",
    "        predict = logReg.predict(X_val)\n",
    "        acc = accuracy(y_val, predict)\n",
    "        scores.append(acc)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aba42b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9261862917398945,\n",
       " 0.8708260105448155,\n",
       " 0.8005272407732865,\n",
       " 0.7513181019332161]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = hypTune(X_train, y_train, X_val, y_val)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38e800",
   "metadata": {},
   "source": [
    "## Forward selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83f70d",
   "metadata": {},
   "source": [
    "### Psuedocode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ed93c",
   "metadata": {},
   "source": [
    "1. Start with empty SF set $A = \\emptyset$\n",
    "2. Initialise candidate set to be all original attributes $A_c = A$\n",
    "3. Find attribute $a_i$ with highest filter score\n",
    "4. Remove feature $a_i$ from candidate set: $A_c \\gets A \\cap a_i$\n",
    "5. Add feature $a_i$ to SF set:$A_s \\gets A_s \\cup a_i$\n",
    "6. Repeat steps 3-5 until convergence\n",
    "\n",
    "Filter types:\n",
    "- Correlation\n",
    "- Mutual information\n",
    "- Entropy\n",
    "- Classification rate\n",
    "- Regression score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e01e5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance_logistic_regression(X, y, feature_names=None):\n",
    "    \"\"\"\n",
    "    Compute and plot feature importance using Logistic Regression coefficients.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Input feature matrix (numpy array or pandas DataFrame).\n",
    "    - y: Target variable (numpy array or pandas Series).\n",
    "    - feature_names: List of feature names (optional).\n",
    "    \n",
    "    Returns:\n",
    "    - feature_importance: Array of feature importances (absolute coefficients).\n",
    "    \"\"\"\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    feature_importance = np.abs(model.coef_[0])  # Take the absolute values of coefficients\n",
    "    \n",
    "    if feature_names is None:\n",
    "        feature_names = [f\"Feature {i}\" for i in range(X.shape[1])]\n",
    "    \n",
    "    # Sort feature importance in descending order\n",
    "    sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "    feature_importance = feature_importance[sorted_idx]\n",
    "    feature_names = [feature_names[i] for i in sorted_idx]\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(range(len(feature_importance)), feature_importance, align='center')\n",
    "    plt.xticks(range(len(feature_importance)), feature_names, rotation=90)\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Feature Importance (Absolute Coefficient)')\n",
    "    plt.title('Feature Importance (Logistic Regression)')\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_importance\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have X (feature matrix) and y (target variable)\n",
    "# feature_importance = plot_feature_importance_logistic_regression(X, y, feature_names=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "181cdc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
       "       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
       "       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
       "       'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
       "       'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
       "       'ring-type', 'spore-print-color', 'population', 'habitat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = X_train.columns\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17bf8bdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6792/2371031904.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportant_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_feature_importance_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol_names\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6792/1272730886.py\u001b[0m in \u001b[0;36mplot_feature_importance_logistic_regression\u001b[0;34m(X, y, feature_names)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mfeature_importance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Take the absolute values of coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "important_features = plot_feature_importance_logistic_regression(X_train, y_train,col_names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "330f7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_selection(X, y, model, stopping_criterion=0.01):\n",
    "    \"\"\"\n",
    "    Perform backward feature selection and return selected features.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Input feature matrix (numpy array or pandas DataFrame).\n",
    "    - y: Target variable (numpy array or pandas Series).\n",
    "    - model: Machine learning model with a fit and predict method (e.g., sklearn classifier).\n",
    "    - stopping_criterion: The tolerance for feature removal. The process stops when accuracy drops below this threshold.\n",
    "    \n",
    "    Returns:\n",
    "    - selected_features: List of selected feature indices.\n",
    "    \"\"\"\n",
    "    num_features = X.shape[1]\n",
    "    selected_features = list(range(num_features))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    base_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    \n",
    "    while len(selected_features) > 1:\n",
    "        max_accuracy = -1\n",
    "        feature_to_remove = None\n",
    "\n",
    "        for feature_index in selected_features:\n",
    "            reduced_features = selected_features.copy()\n",
    "            reduced_features.remove(feature_index)\n",
    "            X_train_reduced = X_train.iloc[:, reduced_features]\n",
    "            X_test_reduced = X_test.iloc[:, reduced_features]\n",
    "\n",
    "            model.fit(X_train_reduced, y_train)\n",
    "            y_pred = model.predict(X_test_reduced)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(accuracy)\n",
    "\n",
    "            if accuracy > max_accuracy:\n",
    "                max_accuracy = accuracy\n",
    "                feature_to_remove = feature_index\n",
    "\n",
    "        if (base_accuracy - max_accuracy) < stopping_criterion:\n",
    "            break\n",
    "\n",
    "        selected_features.remove(feature_to_remove)\n",
    "        base_accuracy = max_accuracy\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have X (feature matrix) and y (target variable)\n",
    "# selected_features = backward_selection(X, y, YourClassifier())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62fa549c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9285714285714286\n",
      "0.9285714285714286\n",
      "0.9296703296703297\n",
      "0.9263736263736264\n",
      "0.9318681318681319\n",
      "0.9296703296703297\n",
      "0.921978021978022\n",
      "0.8879120879120879\n",
      "0.9296703296703297\n",
      "0.9252747252747253\n",
      "0.9230769230769231\n",
      "0.9208791208791208\n",
      "0.9296703296703297\n",
      "0.9296703296703297\n",
      "0.9296703296703297\n",
      "0.9296703296703297\n",
      "0.9241758241758242\n",
      "0.9296703296703297\n",
      "0.9285714285714286\n",
      "0.9263736263736264\n",
      "0.9351648351648352\n",
      "0.9263736263736264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LG_model = LogisticRegression(0.1)\n",
    "selected_fetaures = backward_selection(X_train,y_train, LG_model, 0.9)\n",
    "selected_fetaures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cc3571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(X, y, model, test_size=0.2, min_features=2):\n",
    "    num_features = X.shape[1]\n",
    "    selected_features = []\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    \n",
    "    while len(selected_features) < num_features:\n",
    "        best_feature = None\n",
    "        best_feature_index = None\n",
    "        for feature in range(num_features):\n",
    "            if feature in selected_features:\n",
    "                continue\n",
    "                \n",
    "            candidate_features = selected_features + [feature]\n",
    "            X_train_subset = X_train.iloc[candidate_features]\n",
    "            X_test_subset = X_test.iloc[candidate_features]\n",
    "            \n",
    "            model.fit(X_train_subset, y_train)\n",
    "            y_pred = model.predict(X_test_subset)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_feature = feature\n",
    "                best_feature_index = candidate_features\n",
    "        \n",
    "        if best_feature is not None:\n",
    "            selected_features.append(best_feature)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    if len(selected_features) < min_features:\n",
    "        print(\"Warning: Minimum number of features not met. Returning top features by importance.\")\n",
    "        selected_features = np.argsort(-model.coef_[0])[:min_features]\n",
    "    \n",
    "    selected_features = np.array(selected_features)  # Convert to NumPy array\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "205f480a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (22,1) and (3638,) not aligned: 1 (dim 1) != 3638 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6792/1547279007.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLG_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mselected_fetaures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLG_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mselected_fetaures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6792/4252857578.py\u001b[0m in \u001b[0;36mforward_selection\u001b[0;34m(X, y, model, test_size, min_features)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mX_test_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcandidate_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6792/3112057055.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, single_feature)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mdw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_predicted\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_predicted\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# update parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (22,1) and (3638,) not aligned: 1 (dim 1) != 3638 (dim 0)"
     ]
    }
   ],
   "source": [
    "LG_model = LogisticRegression(0.1)\n",
    "selected_fetaures = forward_selection(X_train,y_train, LG_model, 0.2)\n",
    "selected_fetaures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cafe9c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324f49e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d515efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use confusion matrix (TP, TN, FP, FN) to visualise the performance\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "ax.matshow(cm, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(x=j, y=i, s=cm[i,j], va='center', ha='center')\n",
    "classes=[\"Edible\", \"poisoness\"]\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "plt.xlabel('Predicted Values',)\n",
    "plt.ylabel('actual Values',);\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5025bdee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
